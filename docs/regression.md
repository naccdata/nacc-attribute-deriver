# V4 Notes

## V4 Typing

Currently, V4 data is saved in FW metadata as strings. This causes issues in the data model validation, which explicitly looks at the source type. As an interim solution, the current code enforces typing on everything defined in the `*missingness.csv` files, since those are the "rules" that get curated and already have typing attached.

**THAT BEING SAID**, this is not comprehensive, and only includes variables explicitly needed for QAF generation at the moment. As such, there still may be numerical/integer values in `file.info.resolved` that are _still strings_ since they are not explicitly handled here. Ideally this typing issue gets resolved further upstream (especially because doing this significnatly increases the runtime), but for now this is a brute-force solution to get things going.

# Regression

The following are known and notable issues and inconsistencies in how the legacy code derived variables and what we are changing it to going forward starting with the new system and V4. You may also find `# REGRESSION` comments in the code for more context.

## Generally

* For missingness, there are a lot of inconsistencies on when things are set to -4 based on relevance to the form version. The legacy had to hardcode all of these, and it seems several slipped through the cracks/accidentally got set to something anyways. Going forward, we are using `config/uds_ded_matrix.csv` to explicitly set something to the missingness value (-4/-4.4/blank) if it is not applicable to the version.
	* In the matrix, 1 = collected in that version, 2 = collected only at IVP and automatically brought across, 0/blank = not applicable 

## Form A3

* `NACCFAM`, `NACCMOM`, and `NACCDAD` (all cross-sectional) followed a rule that if any visit ever set it to 1, it would stay 1, but 0 and 9 could flip/flop. Going forward, we instead allow it to flip-flop between 0 and 1, but 9 will never override the other two.
	* On that note, the legacy code for these variables is particularly incomprehensible. The current code doesn't really help, as it was written to reproduce/interpret the legacy output before applying the above change. But at least it's in Python now and not SAS :)

## Form A4

### V1

In V1, the A4 form was very different and all medications were written in by hand. The legacy code did _something_ to translate these to drug IDs (e.g. d00000 codes), but is extremely unclear how it was doing that mapping, and the general consensus was that it was quite unreliable anyways.

Because we were unable to identify the mechanism used for that mapping, we somewhat rather brute-forced its migration it to the current codebase. We basically took the raw drug write-ins and compared them the output of the legacy QAF to determine the "best mapping" to produce the same results, stored in `drug_ids_v1.csv`.

The creation of this file basically followed a combination of the following:

1. If there was a clear 1 to 1 mapping (one drug listed), set that as the "true mapping". Run this logic every time the overall mappings are updated.
2. Make a histogram of raw drug name and count the instances of drug IDs associated with it; if there is a clear "winner", set that as the mapping.
3. Manual inspection/updating.
4. Run the raw drugs through this mapping and see if it produces the same list of results as the legacy QAF. If not, manually inspect/update and run the above again.

This file is used to do what is essentially a hard-coded mapping. Since the final output is a list that is not in the same order as the raw data, individual mappings might be incorrect if they are paired with another incorrect mapping in the list, but ultimately we care about the final list anyways and as it is not practical to check everything right now

### UDSMEDS

There were several tables in the legacy system - the one used here was generated by:

1. Merging UDSMEDS, UDSMEDS2, and UDSMEDS3
2. Removing duplicates
3. Testing against the legacy QAF to manually resolve different typings.

There could be several names corresponding to the same drug and it is unclear how the legacy code "picked" one, so we based as much as we could based off what was displayed in the QAF. However, there may still be duplicates since not all showed up in the legacy QAF, and in such cases we just use the latest one. Usually the differences are minor anyways.

### MEDS vs Drugs List

In the legacy system there were two tables related to A4:

* FRMCA4G, which records whether the participant has any medications for a visit and what indicates that a corresponding MEDS file should exist in Flywheel
* FRMCA4D, which supplies the actual list of drugs for a visit.

Unfortunately, it seems that there are a handful of cases where for a given visit there was only data in one table but not the other. The legacy code would directly query FRMCA4D (drugs list) to calculate most of the derived variables related to A4, as well as set/adjust the `ANYMEDS` variable. The new system, however, relies on the existence of the MEDS file for the same derived/missingness variables.

As such, for these handful of visits with inconsistent data, their derived/missingness values are equally inconsistent between the old and new derivations (e.g. new system cannot find any drugs so sets all variables correspondingly, while the legacy system was able to find drugs and sets it correspondingly, or vice versa). Again, at this point we have decided for this to be an acceptable discrepancy, since such inconsistencies should not have allowed a packet to be finalized to begin with.

## Form B9

* `NACCBEHF`, `NACCBEFX`, `NACCCGFX`, `NACCCOGF`, and `NACCMOTF` are all supposed to be cross-sectional, but the legacy code was treating them as longitudinal values (e.g. they have different values across visits). This will be fixed to enforce the intended cross-sectional nature going forward.

## Form D1a

* `NACCMCII`: Legacy code seems to not have been correctly considering the 8 condition, especially in regards to the initial visit - for example, even if there was MCI at the initial visit, it would NOT set it to 8. I'm still investigating exactly what it's doing wrong just for regression testing, but it will be fixed going forward.
